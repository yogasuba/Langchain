# ğŸ“˜ Document Q&A System

A flexible **document question-answering system** that can run both **with OpenAI APIs** and **completely locally** without any external services.

---

## âœ¨ Features

- ğŸ“„ **Support for PDF and Text documents**  
- ğŸ” **Semantic search** using vector embeddings  
- ğŸ’¬ **Question-answering** with relevant context  
- ğŸŒ **Optional OpenAI integration** for advanced responses  
- ğŸ’¯ **100% local mode available** (no internet required)  
- ğŸš€ **Fast and efficient document processing**

---

## âš™ï¸ Installation

### **Prerequisites**

- Python 3.8+
- `pip` package manager

### **Install Dependencies**

```bash
# Basic installation
pip install langchain langchain-community langchain-text-splitters chromadb

# For local embeddings (FREE mode)
pip install sentence-transformers torch

# For OpenAI integration (optional)
pip install langchain-openai openai

# For PDF support
pip install pypdf

ğŸ§  Usage
Method 1: Local Mode (FREE - No API Keys Required)

Run the system completely locally without any external services:

python poc_local.py


Features:

Uses local embedding model (all-MiniLM-L6-v2)

Works fully offline after first run

No costs or API limits

Performs document search and retrieval

Method 2: OpenAI Mode (With API Key)

Run with OpenAI for enhanced question-answering:

# Set your OpenAI API key
set OPENAI_API_KEY=your_api_key_here

# Run the script
python poc.py


Features:

Advanced GPT-powered responses

Better contextual understanding

More natural language generation


ğŸ“‚ File Structure
document-qa-system/
â”‚
â”œâ”€â”€ poc.py                 # Main script with OpenAI integration
â”œâ”€â”€ poc_local.py           # Completely local version
â”œâ”€â”€ sample.txt             # Example document
â”œâ”€â”€ chroma_db/             # Vector database storage
â””â”€â”€ README.md              # This file


ğŸ” How It Works

Document Loading â€“ Reads your PDF or text files

Text Splitting â€“ Breaks documents into manageable chunks

Embedding Generation â€“ Converts text to numerical vectors

Local: Uses HuggingFace models

OpenAI: Uses OpenAIâ€™s embedding API

Vector Storage â€“ Stores embeddings in ChromaDB

Similarity Search â€“ Finds relevant sections for queries

Answer Generation â€“ Provides answers based on retrieved context

ğŸ“„ Supported Document Formats
Format	Description
PDF (.pdf)	Research papers, manuals, books
Text (.txt)	Notes, articles, documentation
ğŸ’¬ Example Questions to Ask
For Technical Documents:

What is the main concept discussed?

Explain [technical term] in simple terms

What are the key findings?

How does [process] work?

For Research Papers:

What is the research methodology?

What are the conclusions?

What problem does this solve?

What data was used?

For Manuals/Guides:

How do I perform [specific task]?

What are the system requirements?

Troubleshooting steps for [issue]

âš™ï¸ Configuration
Local Mode Settings

Embedding Model: sentence-transformers/all-MiniLM-L6-v2

Chunk Size: 1000 characters

Chunk Overlap: 200 characters

Similarity Search: Top 3 results

OpenAI Mode Settings

Model: gpt-3.5-turbo or gpt-4

Temperature: 0 (deterministic responses)

Max Tokens: Based on context

ğŸ§° Troubleshooting
Common Issues

Module Not Found Errors

pip install --upgrade langchain-community


PDF Reading Issues

pip install --upgrade pypdf


Local Model Download Problems

Check internet connection for first-time download

Ensure sufficient disk space (~400MB for embeddings model)

OpenAI API Errors

Verify API key is set correctly

Check billing and usage limits

Ensure organization settings allow API access

âš¡ Performance Tips

For large documents, increase chunk size to 1500â€“2000 characters

Use SSD storage for faster vector database operations

Close other memory-intensive applications when processing large files

For better local performance, consider using GPU with CUDA support

ğŸ”’ Privacy & Security
Local Mode

âœ… All processing happens on your machine
âœ… No data sent to external services
âœ… Complete privacy and control

OpenAI Mode

âš ï¸ Document content sent to OpenAI servers
ğŸ”’ Follows OpenAI's data usage policies
ğŸ“Š Refer to OpenAIâ€™s privacy policy
 for details

ğŸ§¾ License

This project is released under the MIT License.
Feel free to modify and use it for your own projects.
